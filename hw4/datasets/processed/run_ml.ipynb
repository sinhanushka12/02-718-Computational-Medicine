{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "train_df = pd.read_csv('processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features and labels out from the dataset as X and y\n",
    "columns_to_keep = [col for col in train_df.columns if col not in ['PatientID', 'Outcome', 'LOS']]\n",
    "X = train_df[columns_to_keep]\n",
    "y_classification = train_df['Outcome']\n",
    "y_regression = train_df['LOS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "def run_dt(f, outcome, los, task, seed, max_depth):\n",
    "    if task == 'classification': \n",
    "        accuracy_scores = []\n",
    "        for i, j in cross_validation.split(f, outcome):\n",
    "            f_train, f_test = f.iloc[i], f.iloc[j]\n",
    "            outcome_train, outcome_test = outcome.iloc[i], outcome.iloc[j]\n",
    "            DT_model = DecisionTreeClassifier(random_state=seed, max_depth=max_depth)\n",
    "            DT_model.fit(f_train, outcome_train)\n",
    "            outcome_pred = DT_model.predict(f_test)\n",
    "            accuracy = accuracy_score(outcome_test, outcome_pred)\n",
    "            accuracy_scores.append(accuracy)\n",
    "        return f' {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}'\n",
    "    elif task == 'regression':\n",
    "        mse_scores = []\n",
    "        for i, j in cross_validation.split(f, los):\n",
    "            f_train, f_test = f.iloc[i], f.iloc[j]\n",
    "            los_train, los_test = los.iloc[i], los.iloc[j]\n",
    "            DT_model = DecisionTreeRegressor(random_state=seed, max_depth=max_depth)\n",
    "            DT_model.fit(f_train, los_train)\n",
    "            los_pred = DT_model.predict(f_test)\n",
    "            mse = mean_squared_error(los_test, los_pred)\n",
    "            mse_scores.append(mse)\n",
    "        return f' {np.mean(mse_scores):.4f} ± {np.std(mse_scores):.4f}'\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "def run_rf(f, outcome, los, task, estimators, seed, max_depth):\n",
    "    if task == 'classification': \n",
    "        accuracy_scores = []\n",
    "        for i, j in cross_validation.split(f, outcome):\n",
    "            f_train, f_test = f.iloc[i], f.iloc[j]\n",
    "            outcome_train, outcome_test = outcome.iloc[i], outcome.iloc[j]\n",
    "            rf_model = RandomForestClassifier(n_estimators= estimators,random_state=seed, max_depth=max_depth)\n",
    "            rf_model.fit(f_train, outcome_train)\n",
    "            outcome_pred = rf_model.predict(f_test)\n",
    "            accuracy = accuracy_score(outcome_test, outcome_pred)\n",
    "            accuracy_scores.append(accuracy)\n",
    "        return f' {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}'\n",
    "    elif task == 'regression':\n",
    "        mse_scores = []\n",
    "        for i, j in cross_validation.split(f, los):\n",
    "            f_train, f_test = f.iloc[i], f.iloc[j]\n",
    "            los_train, los_test = los.iloc[i], los.iloc[j]\n",
    "            rf_model = RandomForestRegressor(n_estimators= estimators,random_state=seed, max_depth=max_depth)\n",
    "            rf_model.fit(f_train, los_train)\n",
    "            los_pred = rf_model.predict(f_test)\n",
    "            mse = mean_squared_error(los_test, los_pred)\n",
    "            mse_scores.append(mse)\n",
    "        return f' {np.mean(mse_scores):.4f} ± {np.std(mse_scores):.4f}'\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "def run_xgboost(f, outcome, los, task, booster, estimators, max_depth):\n",
    "    if task == 'classification': \n",
    "        accuracy_scores = []\n",
    "        for i, j in cross_validation.split(f, outcome):\n",
    "            f_train, f_test = f.iloc[i], f.iloc[j]\n",
    "            outcome_train, outcome_test = outcome.iloc[i], outcome.iloc[j]\n",
    "            xgb_model = xgb.XGBClassifier(booster= booster, n_estimators= estimators, max_depth=max_depth)\n",
    "            xgb_model.fit(f_train, outcome_train)\n",
    "            outcome_pred = xgb_model.predict(f_test)\n",
    "            accuracy = accuracy_score(outcome_test, outcome_pred)\n",
    "            accuracy_scores.append(accuracy)\n",
    "        return f' {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}'\n",
    "    elif task == 'regression':\n",
    "        mse_scores = []\n",
    "        for i, j in cross_validation.split(f, los):\n",
    "            f_train, f_test = f.iloc[i], f.iloc[j]\n",
    "            los_train, los_test = los.iloc[i], los.iloc[j]\n",
    "            xgb_model = xgb.XGBRegressor(booster= booster, n_estimators= estimators, max_depth=max_depth)\n",
    "            xgb_model.fit(f_train, los_train)\n",
    "            los_pred = xgb_model.predict(f_test)\n",
    "            mse = mean_squared_error(los_test, los_pred)\n",
    "            mse_scores.append(mse)\n",
    "        return f' {np.mean(mse_scores):.4f} ± {np.std(mse_scores):.4f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "def run_svm(f, outcome, los, task, k, c, g):\n",
    "    if task == 'classification': \n",
    "        accuracy_scores = []\n",
    "        for i, j in cross_validation.split(f, outcome):\n",
    "            f_train, f_test = f.iloc[i], f.iloc[j]\n",
    "            outcome_train, outcome_test = outcome.iloc[i], outcome.iloc[j]\n",
    "            svc_model = SVC(kernel=k, C=c, gamma=g)\n",
    "            svc_model.fit(f_train, outcome_train)\n",
    "            outcome_pred = svc_model.predict(f_test)\n",
    "            accuracy = accuracy_score(outcome_test, outcome_pred)  # Use accuracy_score function\n",
    "            accuracy_scores.append(accuracy)\n",
    "        return f' {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}'\n",
    "    elif task == 'regression':\n",
    "        mse_scores = []\n",
    "        for i, j in cross_validation.split(f, los):\n",
    "            f_train, f_test = f.iloc[i], f.iloc[j]\n",
    "            los_train, los_test = los.iloc[i], los.iloc[j]\n",
    "            svr_model = SVR(kernel=k, C=c, gamma=g)\n",
    "            svr_model.fit(f_train, los_train)\n",
    "            los_pred = svr_model.predict(f_test)\n",
    "            mse = mean_squared_error(los_test, los_pred)\n",
    "            mse_scores.append(mse)\n",
    "        return f' {np.mean(mse_scores):.4f} ± {np.std(mse_scores):.4f}'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOS Prediction:\n",
      "1. Decision Tree: (random_state: 42, max_depth: 5),  52.2216 ± 20.9596\n",
      " \t \t (random_state: 42, max_depth: 10),  62.3406 ± 21.6673\n",
      "2. Random Forest: (n_estimators: 50, random_state: 42, max_depth: 5),  40.3391 ± 17.6600\n",
      " \t \t (n_estimators: 50, random_state: 42, max_depth: 10),  40.1438 ± 17.3493\n",
      "3. XgBoost: (booster: gbtree, random_state: 42, max_depth: 5),  42.2067 ± 13.7943\n",
      " \t \t (booster: dart, random_state: 42, max_depth: 10),  44.0573 ± 18.4344\n",
      "4. SVM: (kernel: rbf, C: 0.1, gamma: scale),  43.9145 ± 19.2166\n",
      " \t \t (kernel: rbf, C: 1.0, gamma: auto),  48.5667 ± 17.6198\n",
      " \n",
      " \n",
      "Outcome  Prediction:\n",
      "1. Decision Tree: (random_state: 42, max_depth: 5),  0.9094 ± 0.0662\n",
      " \t \t (random_state: 42, max_depth: 10),  0.9004 ± 0.0801\n",
      "2. Random Forest: (n_estimators: 50, random_state: 42, max_depth: 5),  0.9640 ± 0.0345\n",
      " \t \t (n_estimators: 50, random_state: 42, max_depth: 10),  0.9670 ± 0.0409\n",
      "3. XgBoost: (booster: gbtree, random_state: 42, max_depth: 5),  0.9730 ± 0.0365\n",
      " \t \t (booster: dart, random_state: 42, max_depth: 10),  0.9730 ± 0.0365\n",
      "4. SVM: (kernel: rbf, C: 0.1, gamma: scale),  0.8944 ± 0.0650\n",
      " \t \t (kernel: rbf, C: 1.0, gamma: auto),  0.5438 ± 0.0517\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # dt\n",
    "    dt_mse_combination1 = run_dt(X, y_classification, y_regression, 'regression', 42, 5)\n",
    "    dt_mse_combination2 = run_dt(X, y_classification, y_regression, 'regression', 42, 10)\n",
    "\n",
    "    # rf\n",
    "    rf_mse_combination1 = run_rf(X, y_classification, y_regression, 'regression', 50, 42, 5)\n",
    "    rf_mse_combination2 = run_rf(X, y_classification, y_regression, 'regression', 50, 42, 10)\n",
    "    \n",
    "    # xgboost\n",
    "    xgboost_mse_combination1 = run_xgboost(X, y_classification, y_regression, 'regression', 'gbtree', 42, 5)\n",
    "    xgboost_mse_combination2 = run_xgboost(X, y_classification, y_regression, 'regression', 'dart', 42, 10)\n",
    "    \n",
    "    # svm\n",
    "    svm_mse_combination1 = run_svm(X, y_classification, y_regression, 'regression', 'rbf', 0.1, 'scale')\n",
    "    svm_mse_combination2 = run_svm(X, y_classification, y_regression, 'regression', 'rbf', 1.0, 'auto')\n",
    "\n",
    "    # Results for LOS prediction\n",
    "    print('LOS Prediction:')\n",
    "    print(\"1. Decision Tree: (random_state: 42, max_depth: 5), {}\\n \\t \\t (random_state: 42, max_depth: 10), {}\".format(dt_mse_combination1, dt_mse_combination2))\n",
    "    print(\"2. Random Forest: (n_estimators: 50, random_state: 42, max_depth: 5), {}\\n \\t \\t (n_estimators: 50, random_state: 42, max_depth: 10), {}\".format(rf_mse_combination1, rf_mse_combination2))\n",
    "    print(\"3. XgBoost: (booster: gbtree, random_state: 42, max_depth: 5), {}\\n \\t \\t (booster: dart, random_state: 42, max_depth: 10), {}\".format(xgboost_mse_combination1, xgboost_mse_combination2))\n",
    "    print(\"4. SVM: (kernel: rbf, C: 0.1, gamma: scale), {}\\n \\t \\t (kernel: rbf, C: 1.0, gamma: auto), {}\".format(svm_mse_combination1, svm_mse_combination2))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\" \")\n",
    "    # dt\n",
    "    dt_acc_combination1 = run_dt(X, y_classification, y_regression, 'classification', 42, 5)\n",
    "    dt_acc_combination2 = run_dt(X, y_classification, y_regression, 'classification', 42, 10)\n",
    "\n",
    "    # rf\n",
    "    rf_acc_combination1 = run_rf(X, y_classification, y_regression, 'classification', 50, 42, 5)\n",
    "    rf_acc_combination2 = run_rf(X, y_classification, y_regression, 'classification', 50, 42, 10)\n",
    "    \n",
    "    # xgboost\n",
    "    xgboost_acc_combination1 = run_xgboost(X, y_classification, y_regression, 'classification', 'gbtree', 42, 5)\n",
    "    xgboost_acc_combination2 = run_xgboost(X, y_classification, y_regression, 'classification', 'dart', 42, 10)\n",
    "    \n",
    "    # svm\n",
    "    svm_acc_combination1 = run_svm(X, y_classification, y_regression, 'classification', 'rbf', 0.1, 'scale')\n",
    "    svm_acc_combination2 = run_svm(X, y_classification, y_regression, 'classification', 'rbf', 1.0, 'auto')\n",
    "\n",
    "    # Results for Outcome Prediction\n",
    "    print('Outcome  Prediction:')\n",
    "    print(\"1. Decision Tree: (random_state: 42, max_depth: 5), {}\\n \\t \\t (random_state: 42, max_depth: 10), {}\".format(dt_acc_combination1, dt_acc_combination2))\n",
    "    print(\"2. Random Forest: (n_estimators: 50, random_state: 42, max_depth: 5), {}\\n \\t \\t (n_estimators: 50, random_state: 42, max_depth: 10), {}\".format(rf_acc_combination1, rf_acc_combination2))\n",
    "    print(\"3. XgBoost: (booster: gbtree, random_state: 42, max_depth: 5), {}\\n \\t \\t (booster: dart, random_state: 42, max_depth: 10), {}\".format(xgboost_acc_combination1, xgboost_acc_combination2))\n",
    "    print(\"4. SVM: (kernel: rbf, C: 0.1, gamma: scale), {}\\n \\t \\t (kernel: rbf, C: 1.0, gamma: auto), {}\".format(svm_acc_combination1, svm_acc_combination2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Serum chloride</th>\n",
       "      <th>Prothrombin time</th>\n",
       "      <th>eosinophils(%)</th>\n",
       "      <th>Alkaline phosphatase</th>\n",
       "      <th>albumin</th>\n",
       "      <th>...</th>\n",
       "      <th>γ-glutamyl transpeptidase</th>\n",
       "      <th>International standard ratio</th>\n",
       "      <th>basophil count(#)</th>\n",
       "      <th>mean corpuscular hemoglobin</th>\n",
       "      <th>serum sodium</th>\n",
       "      <th>thrombocytocrit</th>\n",
       "      <th>glutamic-pyruvic transaminase</th>\n",
       "      <th>eGFR</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>LOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>374.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>128.20</td>\n",
       "      <td>23.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>143.0</td>\n",
       "      <td>27.40</td>\n",
       "      <td>...</td>\n",
       "      <td>176.0</td>\n",
       "      <td>2.1050</td>\n",
       "      <td>0.035</td>\n",
       "      <td>30.15</td>\n",
       "      <td>164.70</td>\n",
       "      <td>0.130</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>69.40</td>\n",
       "      <td>118.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>101.25</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>50.5</td>\n",
       "      <td>38.65</td>\n",
       "      <td>...</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>30.35</td>\n",
       "      <td>137.35</td>\n",
       "      <td>0.270</td>\n",
       "      <td>26.5</td>\n",
       "      <td>106.20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>281.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>98.20</td>\n",
       "      <td>16.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>126.0</td>\n",
       "      <td>24.30</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>32.00</td>\n",
       "      <td>139.80</td>\n",
       "      <td>0.090</td>\n",
       "      <td>23.0</td>\n",
       "      <td>58.00</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>104.25</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>47.5</td>\n",
       "      <td>41.05</td>\n",
       "      <td>...</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1.0100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>31.85</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.170</td>\n",
       "      <td>12.5</td>\n",
       "      <td>117.20</td>\n",
       "      <td>72.5</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>97.90</td>\n",
       "      <td>16.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>60.0</td>\n",
       "      <td>31.40</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>31.20</td>\n",
       "      <td>136.10</td>\n",
       "      <td>0.220</td>\n",
       "      <td>33.0</td>\n",
       "      <td>81.40</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>223.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>101.50</td>\n",
       "      <td>14.80</td>\n",
       "      <td>0.05</td>\n",
       "      <td>61.5</td>\n",
       "      <td>27.50</td>\n",
       "      <td>...</td>\n",
       "      <td>34.5</td>\n",
       "      <td>1.1400</td>\n",
       "      <td>0.015</td>\n",
       "      <td>30.00</td>\n",
       "      <td>143.70</td>\n",
       "      <td>0.265</td>\n",
       "      <td>21.5</td>\n",
       "      <td>55.45</td>\n",
       "      <td>107.5</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>304.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>113.40</td>\n",
       "      <td>16.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.20</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.3300</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30.65</td>\n",
       "      <td>156.00</td>\n",
       "      <td>0.110</td>\n",
       "      <td>15.0</td>\n",
       "      <td>69.30</td>\n",
       "      <td>97.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>162.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>101.80</td>\n",
       "      <td>13.40</td>\n",
       "      <td>1.20</td>\n",
       "      <td>66.0</td>\n",
       "      <td>41.90</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0200</td>\n",
       "      <td>0.030</td>\n",
       "      <td>30.60</td>\n",
       "      <td>138.50</td>\n",
       "      <td>0.260</td>\n",
       "      <td>56.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>75.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>102.60</td>\n",
       "      <td>14.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.10</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.1300</td>\n",
       "      <td>0.020</td>\n",
       "      <td>31.90</td>\n",
       "      <td>142.90</td>\n",
       "      <td>0.210</td>\n",
       "      <td>10.0</td>\n",
       "      <td>79.30</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>137.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>101.70</td>\n",
       "      <td>14.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>68.5</td>\n",
       "      <td>33.15</td>\n",
       "      <td>...</td>\n",
       "      <td>23.5</td>\n",
       "      <td>1.1300</td>\n",
       "      <td>0.015</td>\n",
       "      <td>32.30</td>\n",
       "      <td>138.05</td>\n",
       "      <td>0.125</td>\n",
       "      <td>36.0</td>\n",
       "      <td>98.45</td>\n",
       "      <td>68.5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>100.95</td>\n",
       "      <td>14.60</td>\n",
       "      <td>3.00</td>\n",
       "      <td>81.0</td>\n",
       "      <td>39.85</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.1300</td>\n",
       "      <td>0.020</td>\n",
       "      <td>29.90</td>\n",
       "      <td>141.90</td>\n",
       "      <td>0.360</td>\n",
       "      <td>15.0</td>\n",
       "      <td>121.40</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>103.20</td>\n",
       "      <td>12.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>49.0</td>\n",
       "      <td>40.30</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30.80</td>\n",
       "      <td>141.60</td>\n",
       "      <td>0.230</td>\n",
       "      <td>21.0</td>\n",
       "      <td>114.40</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>302.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>129.00</td>\n",
       "      <td>32.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>81.0</td>\n",
       "      <td>33.60</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.0500</td>\n",
       "      <td>0.075</td>\n",
       "      <td>30.00</td>\n",
       "      <td>163.35</td>\n",
       "      <td>0.110</td>\n",
       "      <td>59.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>165.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>170.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>106.60</td>\n",
       "      <td>14.20</td>\n",
       "      <td>4.25</td>\n",
       "      <td>79.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>0.035</td>\n",
       "      <td>25.50</td>\n",
       "      <td>143.90</td>\n",
       "      <td>0.195</td>\n",
       "      <td>19.0</td>\n",
       "      <td>73.80</td>\n",
       "      <td>72.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>104.95</td>\n",
       "      <td>13.05</td>\n",
       "      <td>0.30</td>\n",
       "      <td>39.5</td>\n",
       "      <td>31.50</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.000</td>\n",
       "      <td>31.65</td>\n",
       "      <td>139.60</td>\n",
       "      <td>0.195</td>\n",
       "      <td>18.5</td>\n",
       "      <td>111.25</td>\n",
       "      <td>53.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>238.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>93.95</td>\n",
       "      <td>15.10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>84.0</td>\n",
       "      <td>29.10</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.1900</td>\n",
       "      <td>0.015</td>\n",
       "      <td>32.60</td>\n",
       "      <td>135.90</td>\n",
       "      <td>0.160</td>\n",
       "      <td>17.0</td>\n",
       "      <td>103.30</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.5</td>\n",
       "      <td>101.90</td>\n",
       "      <td>13.90</td>\n",
       "      <td>0.75</td>\n",
       "      <td>66.0</td>\n",
       "      <td>41.90</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0550</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30.80</td>\n",
       "      <td>143.20</td>\n",
       "      <td>0.370</td>\n",
       "      <td>23.0</td>\n",
       "      <td>126.10</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>53.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>106.70</td>\n",
       "      <td>13.60</td>\n",
       "      <td>1.90</td>\n",
       "      <td>87.0</td>\n",
       "      <td>37.90</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0500</td>\n",
       "      <td>0.030</td>\n",
       "      <td>31.70</td>\n",
       "      <td>140.90</td>\n",
       "      <td>0.220</td>\n",
       "      <td>12.0</td>\n",
       "      <td>96.30</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>215.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>102.85</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89.0</td>\n",
       "      <td>29.60</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.2600</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32.20</td>\n",
       "      <td>139.40</td>\n",
       "      <td>0.170</td>\n",
       "      <td>48.0</td>\n",
       "      <td>78.50</td>\n",
       "      <td>86.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>220.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>104.00</td>\n",
       "      <td>14.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65.5</td>\n",
       "      <td>30.95</td>\n",
       "      <td>...</td>\n",
       "      <td>40.5</td>\n",
       "      <td>1.0700</td>\n",
       "      <td>0.015</td>\n",
       "      <td>34.55</td>\n",
       "      <td>141.80</td>\n",
       "      <td>0.110</td>\n",
       "      <td>33.0</td>\n",
       "      <td>71.00</td>\n",
       "      <td>93.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>317.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>96.20</td>\n",
       "      <td>13.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.0</td>\n",
       "      <td>30.10</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>32.80</td>\n",
       "      <td>138.10</td>\n",
       "      <td>0.160</td>\n",
       "      <td>9.0</td>\n",
       "      <td>107.00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>184.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>99.10</td>\n",
       "      <td>12.90</td>\n",
       "      <td>2.00</td>\n",
       "      <td>59.0</td>\n",
       "      <td>41.30</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.020</td>\n",
       "      <td>32.90</td>\n",
       "      <td>138.90</td>\n",
       "      <td>0.230</td>\n",
       "      <td>33.0</td>\n",
       "      <td>112.20</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>301.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>110.70</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>92.0</td>\n",
       "      <td>29.30</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.1700</td>\n",
       "      <td>0.010</td>\n",
       "      <td>29.20</td>\n",
       "      <td>145.80</td>\n",
       "      <td>0.160</td>\n",
       "      <td>59.0</td>\n",
       "      <td>62.20</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>58.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>105.40</td>\n",
       "      <td>14.30</td>\n",
       "      <td>1.20</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.10</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0925</td>\n",
       "      <td>0.030</td>\n",
       "      <td>30.50</td>\n",
       "      <td>142.00</td>\n",
       "      <td>0.320</td>\n",
       "      <td>16.0</td>\n",
       "      <td>118.90</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>144.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.5</td>\n",
       "      <td>102.55</td>\n",
       "      <td>14.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>87.5</td>\n",
       "      <td>39.40</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>32.40</td>\n",
       "      <td>139.85</td>\n",
       "      <td>0.275</td>\n",
       "      <td>26.5</td>\n",
       "      <td>48.70</td>\n",
       "      <td>128.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>247.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>105.80</td>\n",
       "      <td>20.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.0</td>\n",
       "      <td>27.50</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.7400</td>\n",
       "      <td>0.005</td>\n",
       "      <td>34.85</td>\n",
       "      <td>138.85</td>\n",
       "      <td>0.075</td>\n",
       "      <td>12.0</td>\n",
       "      <td>76.40</td>\n",
       "      <td>76.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>36.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>95.20</td>\n",
       "      <td>13.70</td>\n",
       "      <td>1.80</td>\n",
       "      <td>84.5</td>\n",
       "      <td>33.70</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0600</td>\n",
       "      <td>0.015</td>\n",
       "      <td>33.05</td>\n",
       "      <td>134.80</td>\n",
       "      <td>0.290</td>\n",
       "      <td>71.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>350.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>92.70</td>\n",
       "      <td>16.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>56.0</td>\n",
       "      <td>29.10</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>32.10</td>\n",
       "      <td>134.10</td>\n",
       "      <td>0.170</td>\n",
       "      <td>30.0</td>\n",
       "      <td>48.90</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>341.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>107.60</td>\n",
       "      <td>16.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>31.75</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.3500</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30.40</td>\n",
       "      <td>146.95</td>\n",
       "      <td>0.230</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60.55</td>\n",
       "      <td>97.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>337.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>103.70</td>\n",
       "      <td>14.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.0</td>\n",
       "      <td>38.20</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.1400</td>\n",
       "      <td>0.015</td>\n",
       "      <td>31.60</td>\n",
       "      <td>138.30</td>\n",
       "      <td>0.180</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.70</td>\n",
       "      <td>219.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PatientID   Age  Sex  Outcome  hemoglobin  Serum chloride  \\\n",
       "0       374.0  33.0  1.0      1.0       119.0          128.20   \n",
       "1        21.0  39.0  1.0      0.0       137.0          101.25   \n",
       "2       281.0  81.0  0.0      1.0       120.0           98.20   \n",
       "3        11.0  32.0  1.0      0.0       150.0          104.25   \n",
       "4       276.0  73.0  1.0      1.0       148.0           97.90   \n",
       "5       223.0  82.0  1.0      1.0       165.0          101.50   \n",
       "6       304.0  67.0  1.0      1.0       117.0          113.40   \n",
       "7       162.0  57.0  1.0      0.0       163.0          101.80   \n",
       "8        75.0  88.0  0.0      0.0       110.0          102.60   \n",
       "9       137.0  60.0  1.0      0.0       133.0          101.70   \n",
       "10        5.0  29.0  0.0      0.0       130.0          100.95   \n",
       "11       32.0  34.0  1.0      0.0       124.0          103.20   \n",
       "12      302.0  67.0  1.0      1.0       158.0          129.00   \n",
       "13      170.0  69.0  0.0      0.0        98.5          106.60   \n",
       "14       24.0  57.0  1.0      0.0       119.0          104.95   \n",
       "15      238.0  57.0  1.0      1.0       135.0           93.95   \n",
       "16       17.0  27.0  0.0      0.0       112.5          101.90   \n",
       "17       53.0  47.0  1.0      0.0       141.0          106.70   \n",
       "18      215.0  70.0  1.0      1.0       123.0          102.85   \n",
       "19      220.0  70.0  1.0      1.0       126.5          104.00   \n",
       "20      317.0  43.0  0.0      1.0        88.0           96.20   \n",
       "21      184.0  51.0  1.0      0.0       143.0           99.10   \n",
       "22      301.0  71.0  0.0      1.0       112.0          110.70   \n",
       "23       58.0  27.0  1.0      0.0       134.0          105.40   \n",
       "24      144.0  70.0  1.0      0.0       116.5          102.55   \n",
       "25      247.0  90.0  1.0      1.0       114.0          105.80   \n",
       "26       36.0  68.0  1.0      0.0       137.0           95.20   \n",
       "27      350.0  73.0  1.0      1.0       143.0           92.70   \n",
       "28      341.0  86.0  1.0      1.0       134.0          107.60   \n",
       "29      337.0  59.0  1.0      1.0       114.0          103.70   \n",
       "\n",
       "    Prothrombin time  eosinophils(%)  Alkaline phosphatase  albumin  ...  \\\n",
       "0              23.25            0.00                 143.0    27.40  ...   \n",
       "1              13.00            0.75                  50.5    38.65  ...   \n",
       "2              16.10            0.00                 126.0    24.30  ...   \n",
       "3              13.30            0.10                  47.5    41.05  ...   \n",
       "4              16.20            0.60                  60.0    31.40  ...   \n",
       "5              14.80            0.05                  61.5    27.50  ...   \n",
       "6              16.60            0.00                  80.0    25.20  ...   \n",
       "7              13.40            1.20                  66.0    41.90  ...   \n",
       "8              14.70            0.40                  46.0    32.10  ...   \n",
       "9              14.60            0.50                  68.5    33.15  ...   \n",
       "10             14.60            3.00                  81.0    39.85  ...   \n",
       "11             12.90            0.30                  49.0    40.30  ...   \n",
       "12             32.20            0.00                  81.0    33.60  ...   \n",
       "13             14.20            4.25                  79.0    36.00  ...   \n",
       "14             13.05            0.30                  39.5    31.50  ...   \n",
       "15             15.10            0.50                  84.0    29.10  ...   \n",
       "16             13.90            0.75                  66.0    41.90  ...   \n",
       "17             13.60            1.90                  87.0    37.90  ...   \n",
       "18             16.00            0.00                  89.0    29.60  ...   \n",
       "19             14.10            0.00                  65.5    30.95  ...   \n",
       "20             13.40            0.00                  57.0    30.10  ...   \n",
       "21             12.90            2.00                  59.0    41.30  ...   \n",
       "22             15.00            0.00                  92.0    29.30  ...   \n",
       "23             14.30            1.20                  50.0    40.10  ...   \n",
       "24             14.30            1.00                  87.5    39.40  ...   \n",
       "25             20.30            0.00                  41.0    27.50  ...   \n",
       "26             13.70            1.80                  84.5    33.70  ...   \n",
       "27             16.40            0.00                  56.0    29.10  ...   \n",
       "28             16.65            0.00                  65.0    31.75  ...   \n",
       "29             14.60            0.00                  68.0    38.20  ...   \n",
       "\n",
       "    γ-glutamyl transpeptidase  International standard ratio  \\\n",
       "0                       176.0                        2.1050   \n",
       "1                        24.5                        0.9800   \n",
       "2                        76.0                        1.3000   \n",
       "3                        17.5                        1.0100   \n",
       "4                        32.0                        1.3000   \n",
       "5                        34.5                        1.1400   \n",
       "6                        12.0                        1.3300   \n",
       "7                        36.0                        1.0200   \n",
       "8                        12.0                        1.1300   \n",
       "9                        23.5                        1.1300   \n",
       "10                       20.0                        1.1300   \n",
       "11                       23.0                        0.9600   \n",
       "12                       52.0                        3.0500   \n",
       "13                       26.0                        1.0900   \n",
       "14                       16.0                        0.9850   \n",
       "15                       22.0                        1.1900   \n",
       "16                       37.0                        1.0550   \n",
       "17                       14.0                        1.0500   \n",
       "18                       84.0                        1.2600   \n",
       "19                       40.5                        1.0700   \n",
       "20                        9.0                        1.0100   \n",
       "21                       18.0                        0.9800   \n",
       "22                       42.0                        1.1700   \n",
       "23                       12.0                        1.0925   \n",
       "24                       45.0                        1.1000   \n",
       "25                       13.0                        1.7400   \n",
       "26                       65.0                        1.0600   \n",
       "27                       40.0                        1.3000   \n",
       "28                       15.0                        1.3500   \n",
       "29                       26.0                        1.1400   \n",
       "\n",
       "    basophil count(#)  mean corpuscular hemoglobin   serum sodium  \\\n",
       "0               0.035                         30.15        164.70   \n",
       "1               0.000                         30.35        137.35   \n",
       "2               0.020                         32.00        139.80   \n",
       "3               0.000                         31.85        139.75   \n",
       "4               0.020                         31.20        136.10   \n",
       "5               0.015                         30.00        143.70   \n",
       "6               0.020                         30.65        156.00   \n",
       "7               0.030                         30.60        138.50   \n",
       "8               0.020                         31.90        142.90   \n",
       "9               0.015                         32.30        138.05   \n",
       "10              0.020                         29.90        141.90   \n",
       "11              0.010                         30.80        141.60   \n",
       "12              0.075                         30.00        163.35   \n",
       "13              0.035                         25.50        143.90   \n",
       "14              0.000                         31.65        139.60   \n",
       "15              0.015                         32.60        135.90   \n",
       "16              0.010                         30.80        143.20   \n",
       "17              0.030                         31.70        140.90   \n",
       "18              0.010                         32.20        139.40   \n",
       "19              0.015                         34.55        141.80   \n",
       "20              0.000                         32.80        138.10   \n",
       "21              0.020                         32.90        138.90   \n",
       "22              0.010                         29.20        145.80   \n",
       "23              0.030                         30.50        142.00   \n",
       "24              0.020                         32.40        139.85   \n",
       "25              0.005                         34.85        138.85   \n",
       "26              0.015                         33.05        134.80   \n",
       "27              0.020                         32.10        134.10   \n",
       "28              0.020                         30.40        146.95   \n",
       "29              0.015                         31.60        138.30   \n",
       "\n",
       "    thrombocytocrit  glutamic-pyruvic transaminase    eGFR  creatinine   LOS  \n",
       "0             0.130                         1508.0   69.40       118.0   4.0  \n",
       "1             0.270                           26.5  106.20        80.0  15.0  \n",
       "2             0.090                           23.0   58.00        82.0   3.0  \n",
       "3             0.170                           12.5  117.20        72.5  13.0  \n",
       "4             0.220                           33.0   81.40        82.0   2.0  \n",
       "5             0.265                           21.5   55.45       107.5   7.0  \n",
       "6             0.110                           15.0   69.30        97.0  25.0  \n",
       "7             0.260                           56.0   86.00        86.0  21.0  \n",
       "8             0.210                           10.0   79.30        58.0   7.0  \n",
       "9             0.125                           36.0   98.45        68.5   8.0  \n",
       "10            0.360                           15.0  121.40        56.0  10.0  \n",
       "11            0.230                           21.0  114.40        74.0  15.0  \n",
       "12            0.110                           59.0   36.50       165.0   4.0  \n",
       "13            0.195                           19.0   73.80        72.0  13.0  \n",
       "14            0.195                           18.5  111.25        53.5  15.0  \n",
       "15            0.160                           17.0  103.30        64.0   6.0  \n",
       "16            0.370                           23.0  126.10        52.0   8.0  \n",
       "17            0.220                           12.0   96.30        83.0   2.0  \n",
       "18            0.170                           48.0   78.50        86.0   7.0  \n",
       "19            0.110                           33.0   71.00        93.5   6.0  \n",
       "20            0.160                            9.0  107.00        61.0   3.0  \n",
       "21            0.230                           33.0  112.20        58.0   4.0  \n",
       "22            0.160                           59.0   62.20        82.0   1.0  \n",
       "23            0.320                           16.0  118.90        76.0   7.0  \n",
       "24            0.275                           26.5   48.70       128.0   9.0  \n",
       "25            0.075                           12.0   76.40        76.0   5.0  \n",
       "26            0.290                           71.0   95.00        65.0   8.0  \n",
       "27            0.170                           30.0   48.90       125.0   0.0  \n",
       "28            0.230                           10.0   60.55        97.5   4.0  \n",
       "29            0.180                           21.0   29.70       219.0  14.0  \n",
       "\n",
       "[30 rows x 56 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df = test_df[train_df.columns]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(['PatientID', 'Outcome', 'LOS'], axis=1) \n",
    "y_test_classification = test_df['Outcome']\n",
    "y_test_regression = test_df['LOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOS Predictions:\n",
      "Random Forest: Mean-squared error score, 28.33211687765665\n",
      " \t \t Explained variance score, 0.16509921147500317\n",
      " \t \t Mean Absolute Error, 3.8037560532800327\n"
     ]
    }
   ],
   "source": [
    "best_regression_model = RandomForestRegressor(n_estimators=50, random_state=42, max_depth=5) \n",
    "best_regression_model.fit(X, y_regression)\n",
    "test__regression_predictions = best_regression_model.predict(X_test)\n",
    "\n",
    "# Performance metric 1\n",
    "mse_test = mean_squared_error(y_test_regression, test__regression_predictions)\n",
    "# Performance metric 2\n",
    "evs = explained_variance_score(y_test_regression, test__regression_predictions)\n",
    "# Performance metric 3\n",
    "mae = mean_absolute_error(y_test_regression, test__regression_predictions)\n",
    "print('LOS Predictions:')\n",
    "print(\"Random Forest: Mean-squared error score, {}\\n \\t \\t Explained variance score, {}\\n \\t \\t Mean Absolute Error, {}\".format(mse_test, evs, mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome Predictions:\n",
      "XgBoost: Accuracy Score: 1.0\n",
      " \t (Precision, recall, f1): (1.0, 1.0, 1.0)\n",
      " \t  Confusion Matrix: [array([15,  0]), array([ 0, 15])]\n"
     ]
    }
   ],
   "source": [
    "best_classification_model = xgb.XGBClassifier(booster= 'gbtree', n_estimators= 42, max_depth=5)\n",
    "best_classification_model.fit(X, y_classification)\n",
    "test_classification_predications = best_classification_model.predict(X_test)\n",
    "\n",
    "# Performance metric 1\n",
    "acc_test = accuracy_score(y_test_classification, test_classification_predications)\n",
    "# Performance metric 2\n",
    "precision = precision_score(y_test_classification, test_classification_predications)\n",
    "recall = recall_score(y_test_classification, test_classification_predications)\n",
    "f1 = f1_score(y_test_classification, test_classification_predications)\n",
    "# Performance metric 3\n",
    "cm = list(confusion_matrix(y_test_classification, test_classification_predications))\n",
    "print('Outcome Predictions:')\n",
    "print(\"XgBoost: Accuracy Score: {}\\n \\t (Precision, recall, f1): {}\\n \\t  Confusion Matrix: {}\".format(acc_test, (precision, recall,f1), cm))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70d57c135da11913b2ad31fa6150ab201732e694e7c1a956b2909783da6a3273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
